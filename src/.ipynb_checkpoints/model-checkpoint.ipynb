{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e97f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numpy import argmax\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Convolution2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbb96e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12584.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13006.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12793.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12721.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12573.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12201.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12273.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12896.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12291.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 12434.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "train_ds = []\n",
    "\n",
    "IMG_SIZE = 128\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "def create_training_data():\n",
    "    DATADIR = \"/home/karol/python_projekty/cv2/sudoku/data/train\"\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            img_array = cv.imread(os.path.join(path, img))\n",
    "            gray = cv.cvtColor(img_array, cv.COLOR_RGB2GRAY)\n",
    "            ret, thresh = cv.threshold(gray, 127, 255, cv.THRESH_BINARY_INV)\n",
    "            train_ds.append([thresh, class_num])\n",
    "\n",
    "\n",
    "create_training_data()\n",
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888433e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4423644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in train_ds:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f39dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4012076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 128, 128, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d9c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Convolution2D(128, 3, 3, input_shape=X.shape[1:], activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Convolution2D(64, 2, 1, activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Convolution2D(32, 2, 1, activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(10),\n",
    "    Activation(\"sigmoid\"),\n",
    "]\n",
    "\n",
    "model = Sequential()\n",
    "for layer in layers:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc8c7479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 4s 8ms/step - loss: 0.4177 - accuracy: 0.8628\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0711 - accuracy: 0.9759\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0485 - accuracy: 0.9856\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0303 - accuracy: 0.9902\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0317 - accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0238 - accuracy: 0.9925\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0196 - accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0187 - accuracy: 0.9938\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0177 - accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99a4199450>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"/home/karol/python_projekty/cv2/sudoku/models/save_at_{epoch}.h5\"\n",
    "    ),\n",
    "]\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(np.array(X), np.array(y), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac364758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 128, 128, 1), found shape=(32, 128, 1, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m img_array \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[1;32m      5\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Create batch axis\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(argmax(predictions))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/karol/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 128, 128, 1), found shape=(32, 128, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    \"/home/karol/python_projekty/cv2/sudoku/data/train/2/img003-00005.png\",\n",
    "    target_size=(128, 128),\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, -2)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(argmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8745ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05019df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbf8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
