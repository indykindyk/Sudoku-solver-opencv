{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acf4476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "778e374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"/home/karol/model_training_data/X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"/home/karol/model_training_data/y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d7b6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a413066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd2acc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.astype('float32')\n",
    "x_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0af8caff",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'true_divide' output from dtype('float64') to dtype('uint8') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-1081101ff71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'true_divide' output from dtype('float64') to dtype('uint8') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "317fbe01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_train[0], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9635bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9175d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=IMG_SHAPE))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b39d91e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,816\n",
      "Trainable params: 18,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a71d9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80e49a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 5s 20ms/step - loss: 4.2526 - accuracy: 0.8350 - val_loss: 0.1971 - val_accuracy: 0.9428\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1, \n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "202e723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c14d3811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = cv.imread(\"Box.png\")\n",
    "test_image = cv.resize(test_image,(28,28))\n",
    "plt.figure()\n",
    "plt.imshow(test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a219e0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_25_input'), name='conv2d_25_input', description=\"created by layer 'conv2d_25_input'\"), but it was called on an input with incompatible shape (None, 28, 28, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_10\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_25\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=uint8)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-71c59d8cd2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/karol/.local/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_10\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_25\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=uint8)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "np.argmax(model.predict(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97479db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
